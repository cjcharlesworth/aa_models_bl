---
title: "Branch Length Summary Stats Analysis"
output: 
  prettydoc::html_pretty:
    theme: "cayman"
params: 
  mini: TRUE
  mini_n: 5
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE, echo= TRUE, include = TRUE)
library(tidyverse)
source("utils.R")
path_to_data <- "./" 
```

## Goal
The primary goal of this analysis is to determine whether branch length summary statistics differ across protein models.

## First let's take a look at some sample id's from the bird, enzyme, and mammal data.

```{r read in the data and make smaller datasets, message=FALSE}


birds_file <- file.path(path_to_data, "bird_empirical_branch_lengths.csv")
mammals_file <- file.path(path_to_data, "mammal_empirical_branch_lengths.csv")
enzymes_file <- file.path(path_to_data, "enzyme_empirical_branch_lengths.csv")


birds   <- read_csv(birds_file) %>% mutate(dataset =  "birds", id = as.character(id))
mammals <- read_csv(mammals_file) %>% mutate(dataset =  "mammals", id = as.character(id))
enzymes <- read_csv(enzymes_file) %>% mutate(dataset =  "enzymes", id = as.character(id))

# Downsample for mini analysis only
minify <- function(df) 
{
  df %>%
    group_by(id) %>% 
    nest() %>%
    ungroup() %>%
    slice(1:params$mini_n) %>% #this takes the first *however many* rows from the dataset. The *however many* is specified by the params$mini_n
    unnest(cols = c(data))
}
if (params$mini == TRUE) #if we want to use the mini versions of the datasets, then use the mini function on each of them!!
{
  minify(birds) -> birds 
  minify(enzymes) -> enzymes
  minify(mammals) -> mammals
}

bind_rows(mammals, enzymes, birds) -> full_data #this is just one big data frame consisting of the three datasets

summarize_branch_lengths(full_data) -> summarized_bl #this data frame will have branch length summary statistics for enzymes, birds, and mammals

print(summarized_bl) 
```
This dataset contains branch length summary statistics (columns) for three selcted id's from the bird, mammal, and enzyme datasets. Moving forward, we will use this dataset to determine if these summary statistics differ across protein models (JTT, WAG, FLU, Poisson, and LG). 

## Analysis of Branchlength Differences Between Models 
Okay, now that we have our mini-dataset, let's begin to see how the branch length summary stats look!

```{r violin function for bl measurements}

Violin_bl_measurements<-function(bl_df, measurement, y_axis_title, plot_title)
{
bl_df%>%
  select({{measurement}}, model, id, ASRV, dataset)%>%
  filter(ASRV==TRUE)%>%
  group_by(model, id, dataset)%>%
  ggplot(aes(x=model, y={{measurement}}, fill=model))+
  geom_violin()+
  geom_point()+
  stat_summary()+
  scale_fill_brewer(palette = "Dark2")+
  labs(x="Model", y=y_axis_title, title=plot_title)
}

```

```{r vizualize branch lengths violin}
Violin_bl_measurements(summarized_bl, treelength, "Treelength", "Estimated Treelengths for Selected Id's")
Violin_bl_measurements(summarized_bl, mean_bl, "Mean_bl", "Estimated Mean Branchlengths for Selected Id's")
Violin_bl_measurements(summarized_bl, max_bl, "Max_bl", "Estimated Maximum Branchlengths for Selected Id's")
```
<br><br>
From this, we first see that FLU *appears* to overestimate the branch length related measurements while Poisson underestimates. The next noticable aspect of these figures is that these distributions appear to be bi-modal. In each of the violins, there are points grouped both at the top and bottom, but why? It can not be due to ASRV being different, since ASRV is `TRUE` for all points in these figures. This leads us to beleive there is a difference in the *datasets themselves* that is causing us to see this bimodal distribution. A quick look at the dataset in the beginning of this document supports our suspicion, as the `enzymes` summary statistics are much higher than those of `birds` or `mammals`. Perhaps it would be interesting to run the analysis without the enzyme data, to see how the models perform under lower-varience conditions. Maybe the overestimation by FLU and the underestimation by Poisson are due to the high variation alone, in which case we could approximate *how much* varience these models can "handle" before they are no longer reliable. 
<br><br>

### Now, Let's continue to address our goal, but this time by utilizing linear models to determine if branch length *summary statistics* do indeed differ across protein models. Specifically, we will look at mean branch length, treelength, and max branchlength.

First, let's see the function that will be used to conduct this analysis:
``` {r, bl_lm function}

bl_lm_type1<-function(input_branchlength_df, dependent_variable_column)
{
  input_branchlength_df %>%
    mutate(ASRV_modified= if_else(ASRV==TRUE, "Yes", "No")) -> df_for_modeling #need to make ASRV non-boolean
  
  lm({{dependent_variable_column}} ~ model+ ASRV_modified+ dataset, data= df_for_modeling) %>% #since we are referring to a column,we need to use curlies
    aov() %>%
    TukeyHSD()->fitted_model
  
  fitted_model$model %>% 
    as_tibble(rownames = "comparison") #this will make the output a little nicer
}


bl_lm_type2<-function(input_branchlength_df, dependent_variable_column)
{
  input_branchlength_df %>%
    mutate(ASRV_modified= if_else(ASRV==TRUE, "Yes", "No")) -> df_for_modeling #need to make ASRV non-boolean
  
  lm({{dependent_variable_column}} ~ model+ ASRV_modified, data= df_for_modeling) %>% #since we are referring to a column,we need to use curlies
    aov() %>%
    TukeyHSD()->fitted_model
  
  fitted_model$model %>% 
    as_tibble(rownames = "comparison") 
  
}


bl_lm_type3<-function(input_branchlength_df, dependent_variable_column)
{
  input_branchlength_df %>%
    mutate(ASRV_modified= if_else(ASRV==TRUE, "Yes", "No")) -> df_for_modeling #need to make ASRV non-boolean
  
  lm({{dependent_variable_column}} ~ model,data= df_for_modeling) %>% #since we are referring to a column,we need to use curlies
    aov() %>%
    TukeyHSD()->fitted_model
  
  fitted_model$model %>% 
    as_tibble(rownames = "comparison") 

}

```

Now, we can plug in different branch length-related summary stats into the `dependent_variable_column` variable in the function. Similarly, we can plug in different datasets by adding a variable for `dataset`. For our analysis, we will conduct (4) linear models for each summary statistic of interest: one with all of the datasets lumped together as they appear in `summarized_bl`, and three individual models for the three respective datasets. Note that we can also change the *predictors* that are used within the model itself. For example, one possibility is `summary stat`~`model`+ `dataset`+`ASRV_modified`. This format is basically asking the question "how well do three factors: the model used (1), the dataset the branchlengths came from (2) and the ASRV (3) explain the variation that is seen in the summary stat of interest? There are two other types of linear models that we can run from modifying this formula. They are as follows: `summary stat`~`model`+ `dataset` and `summary stat`~`model`. We can consoder these three types of linear models as three "types" of models, each with different predictor variables. Overall, this leaves us with 4 type 1 models, 4 type 2 models, and 4 type 3 models for each summary stat of interest. Since we are concerned with three summary stats total, this leaves us with 36 linear models to analyze! 
 <br><br>
 
 First, we will look at mean branch length as our branch length summary statistic of interest.

#### Mean Branch Length
``` {r lm for mean bl}
bl_lm_type1(summarized_bl, summarized_bl$mean_bl)
```

#### Treelength
```{r lm for treelength}
bl_lm_type1(summarized_bl, summarized_bl$treelength)
```

#### Max Branch Length
```{r lm for max bl}
bl_lm_type1(summarized_bl, summarized_bl$max_bl)
```

<br>
From this, the only significant difference that we find between the models' estimates of these summary statistics is between the treelength estimates of Poisson and FLU (p=0.0104). This makes sense when going back to the violin plots above, where the stark difference in treelength estimates between Poisson and FLU can be visualized! It is important to note, however, that these linear models were run with the *mini* versions of the empirical datasets, so differences between the models' estimates of branch length summary statistics may actually be more profound than what is shown here. 

### BRIEF Analysis of Datasets
Thus far, we have really only focused on the differences that exist in branch length estimates between models, but what differences exist between the datasets themselves?

```{r, vizualize differnces in datasets}

summarized_bl%>%
  select(dataset, treelength, mean_bl, max_bl)%>%
  group_by(dataset)%>%
summarize(avg_treelength=mean(treelength), avg_bl=mean(mean_bl), avg_max_bl=mean(max_bl))





summarized_bl%>%
  select(dataset, treelength, mean_bl, max_bl)%>%
  group_by(dataset)%>%
summarize(avg_treelength=mean(treelength), avg_bl=mean(mean_bl), avg_max_bl=mean(max_bl))%>%
  ggplot(aes(x=dataset, y=avg_max_bl, fill=dataset))+
  geom_col()+
theme_classic()+
  labs(title="Differences in Max Branch length Estimates Between Datasets", x="Dataset", y="Average Max Branchlength")+
  scale_fill_brewer(palette = "Dark2")

```
<br><br>
This quick analysis shows us that the enzymes dataset displays MUCH MORE evolutionary change than the other two datasets (at least for the selected id's). An interesting question this brings up is *why* does the enzyme data show so much more evolutionary change than the other two datasets? It could be that the sequences of the selected enzymes are not highly conserved, so they are able to change more throughout time without losing key functions. This is just one possibility of many, though. 

