---
title: "Branch Length Summary Stats Analysis"
output: 
  prettydoc::html_pretty:
    theme: "cayman"
params: 
  mini: TRUE
  mini_n: 5
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE, echo= TRUE, include = TRUE)
library(tidyverse)
source("utils.R")
path_to_data <- "./" 
```

## Goal
The primary goal of this analysis is to determine whether branch length summary statistics differ across protein models.

## First let's take a look at some sample id's from the bird, enzyme, and mammal data.

```{r read in the data and make smaller datasets, message=FALSE}

# using parameters:
#https://rmarkdown.rstudio.com/lesson-6.html
# params$mini is TRUE by default. 


birds_file <- file.path(path_to_data, "bird_empirical_branch_lengths.csv")
mammals_file <- file.path(path_to_data, "mammal_empirical_branch_lengths.csv")
enzymes_file <- file.path(path_to_data, "enzyme_empirical_branch_lengths.csv")


birds   <- read_csv(birds_file) %>% mutate(dataset =  "birds", id = as.character(id))
mammals <- read_csv(mammals_file) %>% mutate(dataset =  "mammals", id = as.character(id))
enzymes <- read_csv(enzymes_file) %>% mutate(dataset =  "enzymes", id = as.character(id))

# Downsample for mini analysis only
minify <- function(df) 
{
  df %>%
    group_by(id) %>% 
    nest() %>%
    ungroup() %>%
    slice(1:params$mini_n) %>%
    unnest(cols = c(data))
}
if (params$mini == TRUE) 
{
  minify(birds) -> birds 
  minify(enzymes) -> enzymes
  minify(mammals) -> mammals
}

bind_rows(mammals, enzymes, birds) -> full_data #this is just one big data frame consisting of the three datasets

summarize_branch_lengths(full_data) -> summarized_bl #this data frame will have branch length summary statistics

summarized_bl
```
This dataset contains branch length summary statistics (columns) for three selcted id's from the bird, mammal, and enzyme datasets. Moving forward, we will use this dataset to determine if these summary statistics differ across protein models (JTT, WAG, FLU, Poisson, and LG). 

## Analysis of Branchlength Differences Between Models 
Okay, now that we have our mini-dataset, let's begin to see how the branch length summary stats look!

```{r violin function for bl measurements}

Violin_bl_measurements<-function(bl_df, measurement, y_axis_title, plot_title)
{
bl_df%>%
  select({{measurement}}, model, id, ASRV, dataset)%>%
  filter(ASRV==TRUE)%>%
  group_by(model, id, dataset)%>%
  ggplot(aes(x=model, y={{measurement}}, fill=model))+
  geom_violin()+
  geom_point()+
  stat_summary()+
  scale_fill_brewer(palette = "Dark2")+
  labs(x="Model", y=y_axis_title, title=plot_title)
}

```

```{r vizualize branch lengths violin}
Violin_bl_measurements(summarized_bl, treelength, "Treelength", "Estimated Treelengths for Selected Id's")
Violin_bl_measurements(summarized_bl, mean_bl, "Mean_bl", "Estimated Mean Branchlengths for Selected Id's")
Violin_bl_measurements(summarized_bl, max_bl, "Max_bl", "Estimated Maximum Branchlengths for Selected Id's")
```
<br><br>
From this, we first see that FLU *appears* to overestimate the branch length related measurements while Poisson underestimates. The next noticable aspect of these figures is that these distributions appear to be bi-modal. In each of the violins, there are points grouped both at the top and bottom, but why? It can not be due to ASRV being different, since ASRV is `TRUE` for all points in these figures. This leads us to beleive there is a difference in the *datasets themselves* that is causing us to see this bimodal distribution. A quick look at the dataset in the beginning of this document supports our suspicion, as the `enzymes` summary statistics are much higher than those of `birds` or `mammals`. Perhaps it would be interesting to run the analysis without the enzyme data, to see how the models perform under lower-varience conditions. Maybe the overestimation by FLU and the underestimation by Poisson are due to the high variation alone, in which case we could approximate *how much* varience these models can "handle" before they are no longer reliable. 
<br><br>

### Now, Let's continue to address our goal, but this time by utilizing linear models to determine if branch length *summary statistics* do indeed differ across protein models. Specifically, we will look at mean branch length, treelength, and max branchlength.

```{r linear model statistic~ protein_model + ASRV+ dataset}
linear_model_function_curlies<-function(input_branchlength_df, dependent_variable_column)
{
  input_branchlength_df %>%
    mutate(ASRV_modified= if_else(ASRV==TRUE, "Yes", "No")) -> df_for_modeling #need to make ASRV non-boolean
  
  lm({{dependent_variable_column}} ~ model+ dataset+ ASRV_modified, data= df_for_modeling) %>% #since we are referring to a column,we need to use curlies
    aov() %>%
    TukeyHSD()->fitted_model
  
  fitted_model$model %>% 
    as_tibble(rownames = "Compare") #this will make the output a little nicer
}

```
#### Mean Branch Length
``` {r lm for mean bl}
linear_model_function_curlies(summarized_bl, summarized_bl$mean_bl)
```

#### Treelength
```{r lm for treelength}
linear_model_function_curlies(summarized_bl, summarized_bl$treelength)
```

#### Max Branch Length
```{r lm for max bl}
linear_model_function_curlies(summarized_bl, summarized_bl$max_bl)
```

<br>
From this, the only significant difference that we find between the models' estimates of these summary statistics is between the treelength estimates of Poisson and FLU (p=0.0104). This makes sense when going back to the violin plots above, where the stark difference in treelength estimates between Poisson and FLU can be visualized! It is important to note, however, that these linear models were run with the *mini* versions of the empirical datasets, so differences between the models' estimates of branch length summary statistics may actually be more profound than what is shown here. 

### BRIEF Analysis of Datasets
Thus far, we have really only focused on the differences that exist in branch length estimates between models, but what differences exist between the datasets themselves?

```{r, vizualize differnces in datasets}

summarized_bl%>%
  select(dataset, treelength, mean_bl, max_bl)%>%
  group_by(dataset)%>%
summarize(avg_treelength=mean(treelength), avg_bl=mean(mean_bl), avg_max_bl=mean(max_bl))





summarized_bl%>%
  select(dataset, treelength, mean_bl, max_bl)%>%
  group_by(dataset)%>%
summarize(avg_treelength=mean(treelength), avg_bl=mean(mean_bl), avg_max_bl=mean(max_bl))%>%
  ggplot(aes(x=dataset, y=avg_max_bl, fill=dataset))+
  geom_col()+
theme_classic()+
  labs(title="Differences in Max Branch length Estimates Between Datasets", x="Dataset", y="Average Max Branchlength")+
  scale_fill_brewer(palette = "Dark2")

```
<br><br>
This quick analysis shows us that the enzymes dataset displays MUCH MORE evolutionary change than the other two datasets (at least for the selected id's). An interesting question this brings up is *why* does the enzyme data show so much more evolutionary change than the other two datasets? It could be that the sequences of the selected enzymes are not highly conserved, so they are able to change more throughout time without losing key functions. This is just one psooibility of many, though. 

